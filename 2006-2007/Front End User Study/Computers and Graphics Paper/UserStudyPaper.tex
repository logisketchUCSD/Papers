% ---------------------------------------------------------------------------
% Author guideline and sample document for EG publication using LaTeX2e input
% D.Fellner, v1.11, Feb 28, 2005

\documentclass{elsart}
\usepackage{ifpdf}
\usepackage{graphicx,amssymb,lineno}
\ifpdf
\usepackage[%
  pdftitle={Instructions for use of the document class
    elsart},%
  pdfauthor={Simon Pepping},%
  pdfsubject={The preprint document class elsart},%
  pdfkeywords={instructions for use, elsart, document class},%
  pdfstartview=FitH,%
  bookmarks=true,%
  bookmarksopen=true,%
  breaklinks=true,%
  colorlinks=true,%
  linkcolor=blue,anchorcolor=blue,%
  citecolor=blue,filecolor=blue,%
  menucolor=blue,pagecolor=blue,%
  urlcolor=blue]{hyperref}
\else
\usepackage[%
  breaklinks=true,%
  colorlinks=true,%
  linkcolor=blue,anchorcolor=blue,%
  citecolor=blue,filecolor=blue,%
  menucolor=blue,pagecolor=blue,%
  urlcolor=blue]{hyperref}
\fi

\usepackage{cite}
\usepackage{verbatim} 
\usepackage{subfigure}

% For backwards compatibility to old LaTeX type font selection.
% Uncomment if your document adheres to LaTeX2e recommendations.
\let\rm=\rmfamily    \let\sf=\sffamily    \let\tt=\ttfamily
\let\it=\itshape     \let\sl=\slshape     \let\sc=\scshape
\let\bf=\bfseries

% end of prologue



\renewcommand\floatpagefraction{.2}
\makeatletter
\def\elsartstyle{%
    \def\normalsize{\@setfontsize\normalsize\@xiipt{14.5}}
    \def\small{\@setfontsize\small\@xipt{13.6}}
    \let\footnotesize=\small
    \def\large{\@setfontsize\large\@xivpt{18}}
    \def\Large{\@setfontsize\Large\@xviipt{22}}
    \skip\@mpfootins = 18\p@ \@plus 2\p@
    \normalsize
}
\@ifundefined{square}{}{\let\Box\square}
\makeatother

\def\file#1{\texttt{#1}}

\pagestyle{plain}
\begin{document}

\begin{frontmatter}
\title{Designing a Sketch Recognition Front-End: User Perception of
Interface Elements}

\author{P. Wais, A. Wolin, M. Weiner, S. Sheehan, S.
Harris and C. Alvarado} \address{Department of Computer
Science, Harvey Mudd College, Claremont, CA}

\ead{\{pwais,awolin,mgweiner,ssheehan,sharris,calvarado\}@hmc.edu}
%\ead[url]{authors.elsevier.com/locate/latex}

\begin{abstract}
   Programs that can recognize students' hand-drawn diagrams have the
   potential to revolutionize education by breaking down the barriers
   between diagram creation and simulation.  Much recent work focuses
   on building robust recognition engines, but understanding how to
   support this new interaction paradigm from a user's perspective is
   an equally important and less well understood problem.  We present
   a user study that investigates four critical sketch recognition
   user interface issues: how users integrate the process of
   triggering recognition into their work, when users prefer to
   indicate which portions of the diagram should be recognized, how
   users prefer to receive recognition feedback, and how users
   perceive recognition errors.  We find that user preferences
   emphasize the importance of system reliability, the minimization of
   distractions, and the maximization of predictability. Based on the
   results of this study, we developed a sketch recognition interface
   to a sketch-based circuit design tool.  Further user studies with
   this complete interface confirm the results of our original
   study and suggest new areas to explore.
\end{abstract}

\begin{keyword}
User interface evaluation, pen-based interfaces, user-centered
design, Wizard of Oz
\end{keyword}
\end{frontmatter}

   
% Contribution: This paper presents the first direct comparison of critical
%  free-sketch recognition user interface mechanisms through the novel
%  application of a Wizard of Oz evaluation methodology.  We present
%  recommendation for developers of sketch recognition user interfaces 
%  as well as an interface for a sketch recognition digital design tool 
%  informed by our results.


% Benefit: The results of our study directly inform key aspects of
%   sketch recognition user interface design (e.g., how to allow users
%   to trigger recognition and how to provide recognition feedback),
%   and recognition algorithm development (e.g., which types of errors
%   to try to avoid). 

% Research areas:
%  Evaluation
%  Pen UIs
%  Recognition of sketches, diagrams... etc.

% For additional keywords I would list:
% Wizard of Oz Study

 

% results:
% users want reliability of button trigger over convenience of gesture
% users want pre-separation over post separation and want seperation tool to require least work
% users want most efficient interface possible
% users want least invasive feedback; feedback that provides most natural transformation
% users want most predictible errors
% users all use more or less the same approach to using our tool


%\begin{classification} % according to http://www.acm.org/class/1998/
%\CCScat{H.5.2}{Information Interfaces and Presentation}{User Interfaces}: 
%\textit{Evaluation/methodology, Interaction styles, Prototyping, User-centered design}
%\end{classification}

%\begin{classification} % according to http://www.acm.org/class/1998/
%\CCScat{I.5.4}{Computing Methodologies}{Pattern Recognition}: \textit{Applications}
%\end{classification}

%\begin{classification} % according to http://www.acm.org/class/1998/
%\CCScat{J.6}{Computer-Aided Engineering}{Computer-aided design}
%\end{classification}

%\begin{classification} % according to http://www.acm.org/class/1998/
%\CCScat{I.3.3}{Computer Graphics}{Line and Curve Generation}
%\end{classification}

%\begin{classification} % according to http://www.acm.org/class/1998/
%\CCScat{H.1.2}{User/Machine Systems}{Human information processing}
%\end{classification}

%\end{abstract}


%-------------------------------------------------------------------------
\section{Introduction}

% example of frustration: += thomas "adapt correct behavior to work for it" is a problem
% intro += crossY CrossY \cite{1029635}
Many engineering classes rely on simulation technologies to help
students understand the systems they design.  Unfortunately, mouse and
keyboard interfaces to these programs are cumbersome.  Students in
these courses draw countless diagrams on paper (or on a Tablet PC)
because sketch-based diagram creation is quicker and more natural.  
In fact, many instructors require students to draw 
diagrams on paper before entering designs into simulation software so
that students focus on their design, not on the software interface.

Systems that can recognize and simulate students' hand-drawn sketches
have the potential to lower the cognitive barrier between students and
simulation software.  However, these systems face their own interface
challenges.

One challenge is how to allow users to trigger recognition and how to
display recognition feedback.  Feedback can be distracting in the
early stages of design \cite{Hong2002Sketch}, but it also can aid
recognition as it can help users adapt their drawing styles to match
the system's expectations.  Researchers have evaluated the usability
of various recognition triggers and feedback mechanisms in isolation
(e.g.,
\cite{Alvarado2001Preserving,Newman2003Denim,LaViola2006Initial}), but
have not compared different techniques directly.

A second challenge is how to allow users to indicate which pieces
of the diagram the system should attempt to recognize.  Students'
homework often consists of a mix of text, equations, and
diagrams. Despite advances in parsing heterogeneous
notes~\cite{Wang2006Parsing}, a recognition system must receive only a
single type of input to be practical.  Most recognition systems allow
the user to draw only one type of input (e.g., electrical
circuits~\cite{Gennari2005Combining}), while a few systems allow the
user to manually select pieces of their drawing to be recognized after
they have finished drawing~\cite{LaViola2006Initial}.  Again, little
is known about which interface users prefer.

A third challenge is to minimize the impact of recognition errors on
usability.  Many systems reduce errors by placing constraints on the
way users can draw symbols, for example enforcing that users pause
between symbols or that strokes do not span more than one symbol
(e.g.,~\cite{Tenneson2005ChemPad,Gennari2005Combining,Hse2005Recognition,Alvarado2004SketchRead}).
Others focus on intuitive error correction mechanisms as a way of
reducing the impact of recognition errors~\cite{Mankoff2000Providing}.
We believe that understanding users' tolerance for different types of
recognition errors can help guide sketch recognition research by
allowing researchers to focus on eliminating errors that have the
biggest impact on usability.


%  through the novel
%application of a Wizard of Oz evaluation methodology.  We present
%  an interface for a sketch recognition digital design tool 
%  informed by our results.
  
To address the above challenges, we present the first direct
comparison of critical free-sketch recognition user interface (UI)
elements.  Unlike prior research, which usually involves a qualitative
analysis of a complete solution, we compare interface elements
directly using a novel application of a Wizard of Oz evaluation
methodology.  Specifically, we evaluate UI mechanisms for triggering
recognition, providing feedback, and separating recognizable from
unrecognized data, and we examine users' perception of different types
of recognition errors.  Our results indicate that:
\begin{itemize}
\item Users prefer to trigger recognition after they are done drawing,
  even when the system produces errors.
\item Users prefer to segregate pieces of the drawing (e.g., diagram
  vs. annotation) at creation time rather than recognition time.
\item Users want recognition feedback to transform and clutter their
  sketch as little as possible (even when they have completely finished sketching).
\item Users prefer errors that are predictable and that allow them to
 understand how to modify their drawing style to prevent future errors.
\end{itemize}


%% Our study addresses the following questions:
%% \begin{itemize}
%% \item How do users integrate the task of triggering recognition into
%% their workflows?  How can the design of a user interface assist in
%% this integration?
%% \item How do users react to and interpret recognition results?  
%% \item How and when do users perfer to indicate which pieces of the
%%   diagram should be recognized? 
%% \item How do recognition errors effect the user experience? 
%% \item In the domain of digital circuit design, what characteristics of
%% a sketch-based system do users find most desirable?
%% \end{itemize}

One important user interface question that we do not address is how
gesture-based or menu-based interfaces compare to free-sketch
recognition interfaces.  For example, users might prefer a reliable
gesture-based system to an error-prone free-sketch recognition system.
Although this question is important, we focus only on free-sketch
recognition interfaces for two reasons.  First, the students we talked
to expressed a strong desire for a system that could simply transform
diagrams they already produce for coursework into recognized circuit schematics;
they did not want to have to learn a whole new language for
interacting with the simulation software.  Second, we cannot compare
free-sketch recognition systems to gesture or menu-based systems until
we better understand how to design effective user interfaces for
these systems.

%% Our study was conducted in a single domain (digital circuit design)
%% and so directly informs the design of a sketch recognition interface
%% for digital circuit design.  However, we believe these preferences may
%% apply to other domains.  \emph{Need a stronger sentence here.}

We used the results of our study to develop a novel interface to the
sketch-based circuit design tool that our research group is
developing.  We describe the interface and present the results of an
initial, informal user study that confirms many of the behaviors we
observed in our initial study as well as suggests additional areas to
explore with future studies.


\section{User Interface Elements}
\label{sec:elements}
This section describes the interface elements and error types we
compared.  We chose a subset of elements used in existing sketch
recognition applications or suggested by six participants in a
prestudy we performed.  This set provides a restricted yet
representative range of options.

%\subsection{Recognition Triggers}
We compared three different methods for triggering recognition:
button, gesture and pause.

\begin{itemize}
\item \textbf{Button Trigger.}  The user triggers
recognition by tapping on a large interface button.  This 
option is reminiscent of traditional recognition systems.  
\item \textbf{Gesture Trigger.}  The user triggers
recognition using a ``check-tap'' gesture (a
check mark followed by a dot).  We selected this element because
many researchers posit the efficiency and naturalness of gestures over 
GUI widgets.  Furthermore, this particular gesture seemed to be 
reliably recognized in informal tests, is not easily 
confused with diagram-relevant symbols,
and is similar to the ``circle-tap'' gesture used in
MathPad$^2$~\cite{LaViola2006Initial}.  
\item \textbf{Automatic (Pause) Trigger.}  The system triggers recognition
automatically after a brief pause (four seconds) in sketching.  We chose
a four-second pause to accommodate different student work paces.
\end{itemize}

%%   We conjectured that system-triggered
%% recognition may entice users to engage in a ``dialog'' with the system
%% (e.g., users will treat the system like an agent).  Furthermore, users
%% might find that system-triggered recognition maximizes sketching
%% efficiency. \emph{Say something about no cognitive overhead for
%%   recognition--it just happens.  Paul's note: see \LaTeX\ comment below 
%%   for pre-study link if that's helpful. }
%% We conjecture that users might find gesture-based
%% triggers more convenient, efficient, and natural.

% Pre-study notes are at: https://www.cs.hmc.edu/twiki/bin/view/Sketchers/UserTestingNotes


%% \begin{figure}[tb]
%%   \centering
%%   \includegraphics{checkTapDemo.png}
%%   \caption{\label{fig:checkTapDemo}
%%            fig G = Check-Tap Gesture.}
%% \end{figure}

\begin{figure}[tb]
  \centering
  \includegraphics[width=.65\linewidth]{feedbackDemo.png}
  \caption{\label{fig:feedbackDemo}
           Text and color feedback comparison.}
\end{figure}

%\subsection{Specifying Strokes to Recognize}

The second issue we explored is how to allow the user to indicate
which strokes the system should recognize.  It is possible to provide
separate sketching panels for notes and diagrams, but when users want
to make annotations directly on the diagram, this setup is infeasible.
We examined two techniques for allowing users to segregate
recognizable strokes from unrecognized strokes:

\begin{itemize}
\item \textbf{Pre-separation: ``Color'' Tool.} This version of the
  interface requires users to separate domain strokes from
  annotation strokes as they draw by toggling between stylus
  modes using a button on the GUI.  The system uses ink color to indicate the
  current mode: in sketch mode, the stylus draws black ink; in
  annotation mode, the stylus draws gray ink (hence we call this
  option the ``color'' tool).
\item \textbf{Post-separation: Lasso Tool.} The user draws sketches
  and annotations freely, but then must lasso-select strokes to be
  recognized (similar to the interaction mechanism in
  MathPad$^{2}$\cite{LaViola2006Initial}).  
\end{itemize}

%\subsection{Feedback Mechanisms}
The third issue we explored is how to display recognition feedback.
We compared two different methods: color feedback and text labels
(Figure~\ref{fig:feedbackDemo}).  We rejected the idea of replacing
the user's strokes with symbols based on lack of common interest in
this idea during pre-studies and the results of previous
work~\cite{Hong2002Sketch}.

\begin{itemize}
\item \textbf{Color Feedback.} The system displays each recognized
symbol in a unique color.  In addition, users can see a text label by
hovering the stylus over the strokes in the symbol.  
\item \textbf{Text-Label Feedback.}  The system draws text labels next
to recognized symbols.
\end{itemize}


%% \textit{I took out these sentences because I'm not sure we want to
%%   hypothesize here.}
%% Color: We conjecture that this
%% feedback mechanism might prove the easiest to interpret and the most
%% comfortable to visually recognize.  

%% Text: We conjecture that this
%% feedback mechanism might prove the easiest to interpret and the most
%% comfortable to visually recognize.  

%\subsection{Impact of Recognition Error}
Finally, we investigated how three types of common recognition errors
impact the user experience: false positives, false negatives and
stroke grouping errors (Figure \ref{fig:errorDemo}).  False positives
occur when the system incorrectly identifies a symbol (e.g., labels an
AND gate as an OR gate); false negatives (or \textit{omissions}) occur
when the system fails to identify a symbol; and grouping errors occur
when the system incorrectly adds or removes adjacent strokes to or
from a symbol.


\begin{figure}[tb]
  \centering
  \includegraphics{errorDemo.png}
  \caption{\label{fig:errorDemo}
           Illustration of different error types.}
\end{figure}

%-------------------------------------------------------------------------
\section{Experimental Design}
For this study, we limited our scope to digital circuit design in order
to keep tasks consistent across all users so as to better
understand how interface decisions (as opposed to domain variability)
affect usability.  Although focusing on a single domain limits the
generality of our results somewhat, the style of the tasks we
explored is representative of structured educational design tasks 
in many fields, such as the sciences and engineering.

\subsection{Tasks and Participants}
Users in our study designed circuits based on truth table function
represen-tations---a common task in an introductory digital design
class.  Figure~\ref{fig:tt-task} gives an example of one of these
tasks.  We allowed users to use any method to create the circuit,
and we did not require them to simplify their circuit (i.e., implement
it using the fewest number of gates), although they could if they
wanted to.  In some cases (described in Section~\ref{sec:design}) we
also asked users to annotate the shortest and longest path through the
circuit they designed.



 \begin{figure}[tb]
 \centering
 \begin{tabular}{p{.85\linewidth}}
 	Please draw a circuit diagram for the following truth table:
 	\end{tabular}

   \subfigure[Truth table task] {
   	\label{fig:tt-task}

 			
      \begin{tabular}{|l|l|l||l|l|}
      \hline 
      \multicolumn{3}{|c||}{Input} & \multicolumn{2}{c|}{Output} \\
      \hline
      A & B & C & F & G \\
      \hline
      0 & 0 & 0 & 0 & 1 \\
      \hline
      0 & 0 & 1 & 0 & 0 \\
      \hline
      0 & 1 & 0 & 0 & 1 \\
      \hline
      0 & 1 & 1 & 0 & 0 \\
      \hline
      1 & 0 & 0 & 0 & 0 \\
      \hline
      1 & 0 & 1 & 0 & 0 \\
      \hline
      1 & 1 & 0 & 1 & 0 \\
      \hline  
      1 & 1 & 1 & 1 & 1 \\
      \hline        
    \end{tabular}
} 
   \subfigure[A possible solution (with color feedback).  The black dot
     denotes the user's stylus.] {
     	\label{fig:tt-solution}
 	\includegraphics[width=0.8\linewidth]{complete.png}  
   }
 	\caption{ A truth table task from our user study}
	\label{fig:task}
 \end{figure}


%\begin{figure*}[tb]
%  \centering
%  \subfigure[Truth table task]{
%  	\label{fig:tt-task}
%    \textit{Given the truth table below, sketch the corresponding schematic}
%    \begin{tabular}[|l|l|l|l]
%      \hline 
%      \multicolumn{3}{l}{Input} & Output \\
%      \hline
%     0 & 0 & 0 & 0 \\
%     \hline
%     0 & 0 & 1 & 1 \\
%     \hline
%      0 & 1 & 0 & 0 \\
%      \hline
%      0 & 1 & 1 & 0 \\
%      \hline
%     1 & 0 & 0 & 1 \\
%      \hline      
%    \end{tabular}
%    \label{fig:tt-task}
%  }
%  \subfigure[Possible solution]{
%%    \includegraphics[width=0.5\linewidth]{Figures/instr_060130_slide11}
%    %\includegraphics[width=\linewidth]{complete.png}
%    \label{fig:tt-result}
%  }
%  \caption{A task from our user study}
%  \label{fig:task}
%\end{figure*}


We used a pre-study to design a set of uniformly difficult tasks.  We
asked participants to rate the difficulty of several tasks and
selected for our study only those tasks that users rated as similarly
difficult.  Participants reported that these tasks were similar in
difficulty to typical homework problems in an introductory digital
design course.

%% Users completed a fixed set of circuit design tasks.  For each task we
%% varied one aspect of the user interface.  We describe the details of
%% each of the user interface elements we varied below.  Each participant
%% completed between three and five tasks, and each session lasted 45-60
%% minutes.

In total, nine people (six male and three female) participated in our
formal tests (not including the pre-studies). All participants were
Harvey Mudd College students who had taken an introductory digital
circuit design class.  All participants had used digital circuit
simulation software (Xilinx) in their coursework.  Six of these
students had previous experience (more than an hour) with a Tablet PC,
and five had taken notes on a Tablet PC during their digital design
course (using Windows Journal or Microsoft OneNote).

\subsection{Basic Interface Design}
We first designed our prototype interface using iterative design
techniques.  Figure~\ref{fig:fullGUIdemo} shows a basic overview of
our final interface, although we modified pieces of this interface to
explore different interface elements.  In this version, the user
sketches (unrecognized) notes in the bottom panel, sketches the
circuit (to be recognized) in the top panel and presses the ``Recognize''
button to trigger recognition.


\begin{figure}[tb]
  \centering \includegraphics[width=0.85\linewidth]{fullGUIdemo.png}
  \caption{Complete sketch recognition interface. }
  \label{fig:fullGUIdemo}
\end{figure}


Users could correct recognition errors only by erasing and redrawing
their strokes.  We did not aim to explore error correction mechanisms,
and this method was adequate for users to complete their tasks.
However, error correction mechanisms deserve attention from future studies as
they are an important element of sketch recognition interfaces.




\subsection{User Studies}
\label{sec:design}
We conducted two separate studies to investigate the four interface
elements described above. In the first study we investigated
recognition triggers and diagram separation tools.  In the second
study we examined recognition feedback and error types. We divided our
investigation into two studies in order to minimize the mental burden and
scheduling commitment on users.

During both user studies we invited all participants to contribute
informal feedback and asked them to fill out questionnaires inspired
by the previous work of Chin \textit{et al.}~\cite{chin88} and
Landay~\cite{landay96thesis}.  Our questionnaires aim to measure user
responses to individual interface elements based on relevant
characteristics we inferred from our pre-study interviews and related
work in sketch recognition user interfaces.

\subsubsection{User Study \#1: Recognition Triggers and Diagram
  Separation} 
\label{sec:study1}
Our first study examined triggers and diagram separation preferences
across five participants.  Each participant completed one truth table
task with each recognition trigger using the multi-paneled interface
depicted in Figure \ref{fig:fullGUIdemo}; we balanced the order of
triggers tested across participants.  Next, each participant completed one
truth table task with each diagram separation tool in a single-paneled
version of our interface.  We prompted participants to label the
shortest and longest path in their circuits and to have the system
recognize only their diagrams (i.e., not the annotations).

After each task, the experimenter prompted users for qualitative
feedback and gave questionnaires asking users to rank the reliability,
efficiency, convenience and overall quality of the interface.  After
completing all tasks, users ranked their preferred feedback and
diagram separation mechanisms.  Users completed study sessions in
30-45 minutes.

This study used two methods to ``recognize'' the user's diagrams and
gestures.  First, our system recognized users' check-tap gestures
using the built-in Microsoft Tablet SDK gesture recognizer.  Some
users' gestures were recognized reliably, but others were not (we
discuss the implications below).  Second, the system simulated
recognition of the users' diagrams by coloring most of the strokes
blue, indicating ``correct recognition,'' but displaying approximately
10\% of the strokes in red, indicating a ``recognition error.''  No
recognition actually occurred, but most users expressed that they genuinely presumed
the recognition results and simulated errors were real.

\subsubsection{User Study \#2: Feedback Mechanisms and Error Types}
Our second study examined recognition feedback and recognition errors
across six participants (including two participants from our first
study).  Each participant again completed one truth table task per
feedback method and per error type, and we balanced the order of
feedback mechanisms and error types, respectively, across users.
Feedback tasks always preceded error tasks.  When completing the
error tasks, users chose the feedback mechanism they preferred.  In all
tasks, users triggered recognition with a button. 

Again after each task, the experimenter prompted users for qualitative
feedback and gave them questionnaires asking them to assess the
reliability, efficiency, convenience and overall quality of the
interface.  After completing all tasks, users ranked which feedback
mechanism they preferred and which errors were most confusing or
difficult.  Users completed study sessions in 45-75 minutes.

This study simulated diagram recognition through a novel application
of a Wizard of Oz technique.  Users worked with a realistic Tablet PC
application while a human ``Wizard'' actively labeled user-drawn
symbols.  Wizard of Oz studies have proven
effective for developing speech recognition
interfaces~\cite{Dahlback1993Wizard,Klemmer2000Suede}, but this is the
first application of Wizard of Oz studies to the design of sketch
recognition systems of which we are aware.  Davis has developed a
Wizard of Oz system to support sketch recognition user interface
development\cite{Davis2007SketchWizard}, but this system was not ready
in time for our study.

Our experimental Wizard of Oz system consists of two Tablet PCs directly 
networked over an Ethernet connection.  As the user sketches on one tablet, the
Wizard actively receives copies of user strokes and labels relevant
symbols on a second tablet.  Once the user triggers recognition, the
Wizard sends a labeled result to the user tablet.  For this stage of
our study, our human subjects committee required us to inform
participants that a human was recognizing their strokes.

%% Our prototype user interface and wizard labeling system were both
%% developed in in C\# 1.1, using Microsoft\textregistered \ Visual
%% Studio\textregistered \ .NET 2003.  Both user and Wizard used HP
%% Compaq tc4200 Tablet PCs running Microsoft\textregistered \
%% Windows\textregistered \ XP Tablet PC Edition 2005.

The Wizard simulated perfect recognition while participants tested
feedback mechanisms.  To test error types, we simulated a 15\%
(approximate) error rate.  We chose this rate because it is a
realistic target for sketch recognition systems in the near future.  We
simulated each error type as follows:
\begin{itemize}
\item \textbf{False Positives.} The user end of our Wizard
of Oz system filtered recognition results from the Wizard and randomly
applied incorrect labels to approximately 15\% of the
recognition results.
\item \textbf{False Negatives.} The system again filtered the Wizard's simulated results,
randomly deleting the labels from approximately 15\% of symbols.
\item \textbf{Grouping Errors.}  The
Wizard incorrectly grouped the strokes in
approximately 15\% of symbols drawn, usually giving about 3 to 4
grouping errors per sketch.  
\end{itemize}


%-------------------------------------------------------------------------
\section{Results and Discussion}

In this section we present quantitative and qualitative results of our
study.  In part due to our small sample size, even when users agreed,
many of our survey responses do not show statistically significant
differences.  In many of these cases, however, qualitative feedback
supports patterns in quantitative results.  When users had conflicting
opinions, we summarize these different beliefs so as to inform
interface designers about the range of user preferences.

\subsection{Student Workflow}

Students unanimously reported that they prefer to design their
circuits on a Tablet PC or whiteboard rather than enter them directly
into a simulation tool.  Furthermore, during our study, all of our
participants used almost identical workflows.  When designing a
circuit, each student would write notes or equations, sketch a
circuit, trigger recognition, and then correct recognition errors.
Even when the experimenter reminded users that they could trigger
recognition intermittently during the design process, participants
continued to trigger recognition only after sketching a complete or
significant portion of a circuit.  User comments reveal two reasons
for this workflow: users prefer to focus on the design and
sketching portions of their tasks without interruption, and they
prefer to correct recognition errors in a batch instead of
individually.  

% Not sure if this text has a home.  The comment on Pause trigger
% should go with that discussion.  
%  Another
%user found the Pause Trigger excessively irritating and commented that
%"[recognition] happened when [she] was doing other
%things---distracting."  Another user compared using the tool to
%iteratively writing and compiling software code with an IDE.  This
%user commented that he only triggered recognition after verifying his
%completed sketch because he "fe[lt] like [he] should give it something
%that runs."  


\subsection{Recognition Triggers}



% We conjecture that users might find gesture-based triggers more convenient, efficient, and natural. 
Figure~\ref{fig:qResultsTriggers} summarizes users' responses to
different recognition triggers.  User reactions suggest that high
reliability is the most important characteristic of a recognition
trigger.  Most users were able to trigger recognition successfully
using check-tap only once for every five failures. Though many users
admit the gesture trigger offers a desirable convenience, the majority
of users (n=3) ranked the button trigger higher than the other two
triggers, and users unanimously rated it as highly reliable (Figure
\ref{fig:buttonReliabilityChart}).

The button trigger's high reliability minimizes users' mental effort
and allows them to devise efficient workflows.  One user commented
that the button trigger helped her make her ``approach more
systematic'' and ``figure[] out [the] most efficient way to'' use the
interface.  A second user commented that ``[he could] always get
faster with a tool that works every time.''

The relatively high error rate of the check-tap gesture colored many
users' reactions to this trigger.  The one user that ranked the
gesture trigger as the most desirable was able to trigger recognition
successfully on his first six attempts.  Even still, this user
admitted to seeing only a ``marginal difference'' between the gesture
and button triggers.

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\linewidth]{QuestionnaireResultsRecognitionTrigger.png}
  \caption{\label{fig:qResultsTriggers} Questionnaire results for
           Recognition Triggers. Error bars show one standard
           deviation from the mean response. }
\end{figure}


%% \begin{table}
%%   \centering
%% 	\begin{tabular}{|p{.35\linewidth}|c||c||c|}
%% 	\hline 
%%   Question 										& Button & Gesture & Pause \\
%%   \hline
%%   This trigger was convenient to use. 					& $5.3\pm0.4$ & $4.1\pm2.2$ & $5.4\pm0.9$ \\
%%   \hline
%%   I felt comfortable using this trigger. 						& $6.4\pm0.9$ & $5.9\pm1.4$ & $5.4\pm1.8$ \\
%%   \hline
%%   This trigger was reliable.								& $7.0\pm0.0$ & $3.2\pm2.5$ & $5.6\pm1.5$ \\
%%   \hline
%%   This trigger was efficient.								& $5.6\pm0.5$ & $4.4\pm2.4$ & $5.0\pm1.2$ \\
%%   \hline
%%   My experience using this trigger was satisfying.			& $6.1\pm0.5$ & $5.0\pm2.0$ & $4.4\pm1.5$ \\
%%   \hline
%% 	\end{tabular}
%% 	\caption{Questionnaire results for recognition triggers.  Users are asked to express their feeling on a scale of 
%% 	1 = strongly disagree to 7 = strongly agree.  Standard deviations are given in survey points.}
%% 	\label{tab:TableATriggerData}
%% \end{table}


User reactions to the pause trigger suggest that students may
find the pause trigger acceptable only if it matches the speed of their
thought processes.  Two users commented that a four second pause was
too long, while one user found the pause trigger quite ``distracting''
to her mental flow and suggested a longer pause.  The one user who
ranked the pause trigger as his favorite trigger commented that it
allowed him to ``check as [he] move[d] through creating the diagram.''

\begin{figure}[tb]
  \centering
  \includegraphics[width=1.0\linewidth]{buttonReliable-bigger.png}
  \caption{\label{fig:buttonReliabilityChart} Individual user responses
           to recognition trigger reliability. Each symbol represents
           a single user's response.  ``X''s show mean values.}
\end{figure}

%% Quotes not used:
%% Another user commented with frustration that the Gesture
%%Trigger was "very unreliable" and that the Button Trigger was
%%(desirably) much more "consistent."  

 \subsection{Separation/Annotation Tools}

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\linewidth]{QuestionnaireResultsSepAnnoTools.png}
  \caption{\label{fig:qResultsSepTools}
           Questionnaire results for Separation/Annotation Tools. }
\end{figure}


%% \begin{table}
%%   \centering
%% 	\begin{tabular}{|p{.45\linewidth}|c||c|}
%% 	\hline 
%%   Question 												& Color Tool & Lasso Tool \\
%%   \hline
%%   This annotation tool was convenient to use.						& $6.2\pm0.4$ & $3.2\pm1.3$  \\
%%   \hline
%%   I felt comfortable using this annotation tool.						& $6.6\pm0.5$ & $5.0\pm1.0$  \\
%%   \hline
%%   This annotation tool was reliable.								& $6.0\pm1.0$ & $4.0\pm1.4$  \\
%%   \hline
%%   This annotation tool was efficient.								& $6.5\pm0.5$ & $3.4\pm1.1$  \\
%%   \hline
%%   My experience using this annotation tool was satisfying.	                            & $6.2\pm0.8$ & $3.4\pm1.1$  \\
%%   \hline
%% 	\end{tabular}
%% 	\caption{Questionnaire results for Annotation Tools.}
%% 	\label{tab:TableBAnnotationData}
%% \end{table}


Figure~\ref{fig:qResultsSepTools} summarizes user response to
survey questions about separation techniques.  
Users unanimously preferred the pre-separation (color) tool to the
post-separation (lasso) tool, and all users found the pre-separation
tool more satisfying to use than the post-separation tool (Figure
\ref{fig:annotationSatisfaction}).  Many modal interfaces
traditionally suffer from the problem that users often forget to
toggle to the appropriate mode before performing a task.  However, in
our study, only one of five users forgot to toggle the color tool into
annotation mode before writing notes; furthermore, this user corrected
her mistake immediately.

Two participants commented that the lasso tool constrained the way
they could create their diagrams.  One user described that
the color tool ``required less planning about where and when to write
so as not to screw up [the] lasso[] [gesture].''  Another user
commented that she ``like[d] the [color tool's] ability to draw
annotations wherever [she wanted].''

One issue that may have influenced user responses to the separation
mechanism is that the lasso tool required two check-tap gestures while
the color tool required only one.  Nevertheless, users responded more
negatively to the burden of circling the symbols and the physical
segregating of annotation and schematic strokes than to executing the
gesture.  One user even modified her questionnaire to express her
preferences for annotation tools that hypothetically used the button
trigger rather than check-tap; this user still preferred the color
tool.

%I don't think you need this part.  
% Two users noted that
%both annotation tools suffered from the lack of reliability of the
%Check-Tap Gesture.  Operation of the Lasso Tool requires execution of
%two Check-Tap gestures while operation of the color tool requires only
%one.  Though the reliability issue surrounding the Check-Tap gesture
%colors user reactions to the annotation tools, the fact remains that
%the Lasso Tool requires more effort in circling symbols and the
%physical segregating of notes and schematic strokes.  Clearly the
%potential for confusion over the multi-modal nature of our
%Pre-separation tool imposed a minimal and acceptable burden on users.

\begin{figure}[tb]
  \centering
  \includegraphics[width=1.0\linewidth]{annotationSatisfying.png}
  \caption{\label{fig:annotationSatisfaction} Individual user
           responses to sketch separation method satisfaction.  Error bars are shown for
           one standard deviation.}
           
\end{figure}



\subsection{Feedback Mechanisms}

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\linewidth]{QuestionnaireResultsFeedback.png}
  \caption{\label{fig:qResultsFeedback}
           Questionnaire results for Feedback Mechanisms. }
\end{figure}


%% \begin{table}
%%   \centering
%% 	\begin{tabular}{|p{.45\linewidth}|c||c|}
%% 	\hline 
%%   Question 											& Color & Text-Label \\
%%   \hline
%%   This feedback mechanism produced understandable results.	         & $7.0\pm0.0$ & $6.5\pm0.5$  \\
%%   \hline
%%   I would feel comfortable submitting the result on my screen as a diagram for my homework.
%%   													& $6.5\pm0.5$ & $5.0\pm1.9$  \\
%%   \hline
%%   This feedback helps me work efficiently.						& $6.3\pm1.2$ & $5.1\pm1.6$  \\
%%   \hline
%%   The feedback was distracting.								& $1.1\pm0.4$ & $3.1\pm2.4$  \\
%%   \hline
%%   The feedback was confusing.								& $1.3\pm0.5$ & $2.1\pm1.6$  \\
%%   \hline
%%   My experience using with this feedback mechanism was satisfying.
%%   													& $6.5\pm0.5$ & $5.5\pm1.9$  \\
%%   \hline
%% 	\end{tabular}
%% 	\caption{Questionnaire results for Feedback Mechanisms.}
%% 	\label{tab:TableC1FeedbackData}
%% \end{table}


Figure~\ref{fig:qResultsFeedback} summarizes user survey responses
to feedback mechanisms.  Users unanimously agreed or strongly agreed
that color feedback ``helped them work efficiently'' and ``produced
understandable results''; most users preferred color feedback to
text-label feedback.  Users found text feedback distracting (Figure
\ref{fig:feedbackDistracting}) and that it added an unnecessary mental
burden to the design process.  One user commented that ``The text gets
very cluttered [and] covers up the [sketch's] points of interest
quickly,'' thus interrupting his ability to reason about the diagram.
Another user commented that text labels ``can get a little distracting
with four or five [instances] of the same gate'' and finds the color
feedback ``more elegant'' and ``less redundant.''  Although our
specific text placement may have influenced user perception of the
text labeling feedback mechanism (i.e., sometimes the text obscured
part of the sketch), automatic text placement is a difficult problem,
and any automatic text placement method likely will obscure some
portion of the user's sketch.


Despite the distracting nature of text feedback, color feedback alone
is likely not informative enough.  During the color feedback tests,
each of the six participants immediately hovered her or his stylus
over individual gates to verify the labels.  In
addition, one user commented that she ``like[d] both'' methods of
feedback and found that ``a button to go back and forth [between
feedback mechanisms] would be nice.''

Unlike the work by Zeleznik \textit{et al.}~\cite{Zeleznik2007Designing},
our study did not examine the utility of giving feedback by
displaying beautified versions of the recognized symbols, either in
addition to or in place of the user's strokes.  Users in our prestudy
expressed a general disinterest in this style of feedback, and the
results of our study suggest why.  Users generally disliked clutter in
the diagram, and displaying beautified versions of users' hand-drawn
symbols in addition to the users' original strokes would only increase
this clutter.  On the other hand, removing users' original strokes and
replacing them with beautified symbols would make it difficult for
users to detect recognition errors, as reported by Zeleznik and
Miller~\cite{Zeleznik2007Designing}.

%% We did not develop and test
%% Symbol Replacement due to the lack of common interest in this feedback
%% during our paper prototype study; furthermore, Symbol Replacement
%% Feedback presented technical challenges that would make development
%% impractical for our project's timeframe.  Originally we had considered
%% two possible implementations for Symbol Replacement: one
%% implementation that faintly overlays symbols over a sketch and one
%% implementation that completely erases and replaces user strokes with
%% symbols.  The overlay implementation would have entailed even more
%% sketch obfuscation than that of text labels, thus we anticipate that
%% users would still have preferred Color Feedback.  Moreover, the
%% obfuscation issue that our users raise negates an implementation that
%% entails complete stroke replacement.  Complete stroke replacement
%% would necessarily destroy user strokes and completely prevent users
%% from comparing recognition result labels (e.g., B\'{e}zier Curve
%% symbols) to raw ink symbols.  \textit{I need to edit the above
%% paragraph, but I think the sentiment should stay.  That is, displaying
%% symbols won't work because if you replace the user's strokes they will
%% forget what they drew and not notice errors and if you put the symbol
%% in addition to the strokes it simply creates more clutter.}


%% The
%% informal responses of three other participants corroborate the
%% usefulness of a feature for toggling text labels.  On the other hand,
%% one user specifically opined against such a toggle feature because he
%% found the obfuscation of text feedback made this type of feedback
%% impractical for use.  However, the (sole) user who ranked text
%% feedback as the most desirable asserted that the text labels did not
%% bother him and that "It's easier to distinguish gates by their name
%% rather than [through the use of] different colors."

%% However, color feedback alone is not enough.  

\begin{figure}[tb]
  \centering
  \includegraphics[width=1.0\linewidth]{feedbackDistracting.png}
  \caption{\label{fig:feedbackDistracting}
           Individual user responses to feedback distraction.}
\end{figure}

%% Unused text:
%In contrast, this user found the "hover"
%feature of Color Feedback "less distracting."  The text labels'
%obfuscation of the sketch causes user distress.  In response to the
%issue of obfuscation, one user exclaimed that he "[couldn't] tell what
%gate [he] drew [when he drew] small gates."  Obfuscation taints the
%Text Feedback's aesthetic.  

\subsection{Error Types}

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\linewidth]{QuestionnaireResultsError.png}
  \caption{\label{fig:qResultsErrors}
           Questionnaire results for Error Types. }
\end{figure}

%% \begin{table}
%%   \centering
%% 	\begin{tabular}{|p{.35\linewidth}|c||c||c|}
%% 	\hline 
%%   Question 							& Mislabel & Omission & Group \\
%%   \hline
%%   Detecting errors was difficult. 				& $2.3\pm1.0$ & $2.6\pm1.9$ & $3.5\pm1.2$ \\
%%   \hline
%%   These errors frustrated me. 				& $4.5\pm2.2$ & $4.0\pm2.0$ & $4.1\pm1.3$ \\
%%   \hline
%%   Correcting errors was cumbersome. 		& $3.8\pm1.6$ & $2.8\pm1.5$ & $3.0\pm1.9$ \\
%%   \hline
%%   I attempted to understand why the system produced errors.		
%%   						                            & $3.0\pm1.9$ & $3.3\pm1.6$ & $3.3\pm2.7$ \\
%%   \hline
%%   If I continued to encounter this type of error during further use of this application, I would change how I sketch.																										& $3.0\pm2.1$ & $3.6\pm1.8$ & $4.8\pm1.7$ \\
%%   \hline
%%   These recognition errors confused me.		& $3.5\pm2.1$ & $3.0\pm1.9$ & $3.0\pm1.3$ \\
%%   \hline
%% 	\end{tabular}
%% 	\caption{Questionnaire results for error types.}
%% 	\label{tab:TableDErrorData}
%% \end{table}




%Figure \ref{fig:errorChangeSketch} indicates that users tended to be
%more willing to adapt their sketching styles in response to grouping
%errors.  Though three of six users expressed that they would be
%willing to adapt to the system in order to reduce errors, qualitative
%user reactions were not as consistent.

Figure~\ref{fig:qResultsErrors} summarizes our survey results to error
types.  Users had diverse reactions to recognition errors, and our
quantitative results show no strong trends.  This lack of quantitative
trends may be due in part to an unintended effect of the way we
generated errors.  To keep error rates consistent, the computer system
automatically generated omissions and false positives.  However,
generating grouping errors was too difficult to automate (it would
require a deeper understanding of the sketch in order to split and
merge adjacent groups), so the human Wizard generated grouping errors.
Consequently, false positives and omissions were often more surprising
to users (e.g. a wire classified as an AND gate) than grouping errors.
This effect limits the direct comparison we can make between user
responses to error type, but allows us to better understand the
importance of how users perceive errors based on how well they
understand them.

Our qualitative results suggest that user acceptance of the system is
related not only to absolute error rates but also to how well they
understand and trust the system's recognition.  Generally, our users
initially happily corrected any type of recognition error, but
quickly became frustrated when they could not understand why errors
occurred.  Two users specifically explained that their acceptance of
the system would depend not on the error rate as much as on the
predictability of errors.  One of these users remarked that he would
not be willing to accept a system with the error rate exhibited unless
errors were more predictable and helped him adapt his drawing style to
avoid them.  This user also found false negatives the most confusing
because these errors failed to inform him about ``what to move away
from'' (i.e., how to change his sketching style to reduce errors).  On
the other hand, another user preferred false negatives because it made
him trust the system more when it did recognize his strokes.  Though
related work with speech and handwriting suggests that user acceptance
may improve with lower absolute error
rates~\cite{Wu03ChineseCharacterRecog,Munteanu2006Effect}, our results
illustrate the importance of user perception of error type to
acceptance of the system.  

%END: contemplating related work... would improved error rate really have
%minimized the frustration of crazy 'xor' wires... e.g. would error rate 
%really have an impact here?  hmmm

%% User frustration with errors stems from the inability to establish a
%% reliable and practical mental model of errors.  Generally, users are
%% initially happy to correct any type of recognition error.  Repeated,
%% frustrating errors will inspire users to commit modest yet pragmatic
%% mental effort to understanding errors.  If users fail to learn to
%% predict errors, then frustration will lead them to distrust and reject
%% the system.  Indeed, we found that acceptance of this tool hinged on
%% frustration with, and the predictability of, errors.  Two users
%% remarked that they would accept the current error rate as-is.  Another
%% user also expressed acceptance of the current error rate and remarked
%% that the time required to correct recognition errors with our system
%% was comparable to the time she spent correcting errors while using the
%% WIMP applications her coursework requires.  One user specifically
%% rejected our interface based upon the exhibited error rate and
%% specified that he would only find one recognition error per circuit
%% schematic acceptable; however, this user responded that he was only
%% "kind of" able to predict errors.  The remaining two users both
%% explained that their acceptance of the system depended heavily on the
%% predictability of errors.  One user explained that he would accept the
%% system only if he could reasonably "adapt to" it and that he wanted
%% system errors to help inform his drawing style.  The other emphasized
%% the impact that error rate had on his trust of the system.  This user
%% explicated that he would trade a higher omission error rate for lower
%% grouping and mislabel error rates.  He explained that "if [the system]
%% says 'I don't know what [a sketched symbol] is' then that's a good
%% thing"; a tendency to omit labels rather than incorrectly assign
%% labels helps make the system "safer" to use.  The predictably and
%% acceptance of errors is crucial to an interface's trustworthiness.



We also found that users created dramatically different mental models
of errors.  Two users considered themselves responsible for grouping
errors.  Two users blamed the system for mislabel and omission errors.
One of these users remarked that mislabel and omission errors seemed
``out of context,'' or unpredictable.  Two users specifically remarked
that they did not try to form a mental model of errors.

Qualitative user responses related to frustration with errors
exhibited a general accordance.  Four out of six users responded that
omission errors were the easiest to perceive; users likely find that
the lack of a label is easier to detect than an incorrect label.
Furthermore, four out of six users remarked that the grouping error
was the most confusing type of error despite the fact that these
errors were human-generated.


Finally, although we did not specifically study error correction here,
it clearly impacts users' acceptance of errors and deserves future
study.  In our study users corrected errors by erasing misrecognized
symbols using the eraser end of the stylus and redrawing them.  Three
users remarked that more effective error correction mechanisms would
make dealing with errors less frustrating.  Though most users were
comfortable erasing and redrawing incorrectly
recognized symbols, one user found the erase gesture hard to control
because of the size of the stylus' eraser, and another user requested
a selection tool for erasing large amounts of ink.  In addition to
providing more flexible erasers, future studies should explore
how error correction mechanisms such as N-best lists, explicit symbol
grouping via stroke selection, or multi-modal techniques influence
users' perception of different types of errors.

%% Effective error correction is a non-trivial problem in free-sketch
%% recognition interfaces.  Simple N-best lists may fail for correcting
%% grouping errors.  


%% Three users indicated that they would be
%% inclined to change their sketching styles in order to deal with
%% grouping errors (see Figure \ref{fig:errorChangeSketch}).  One user
%% who responded positively to this survey question (giving a rating of
%% 7/7) also found grouping errors the most confusing; however, this user
%% explained her reaction as a result of the fact that grouping errors
%% were her first exposure to errors.  Two other users who responded
%% positively to the survey question (both giving a rating of 6/7)
%% remarked that they did not attempt to form a mental model of errors.
%% Therefore, users who found grouping errors the most confusing gave
%% survey responses that they were the least likely to change their
%% sketching styles in reaction to grouping errors. \textit{This needs
%% more explanation--it's a little confusing}

%% % plot for survey question "I would change my sketching style of these errors continued..."
%% \begin{figure}[tb]
%%   \centering
%%   \includegraphics[width=1.0\linewidth]{errorChangeSketch.png}
%%   \caption{\label{fig:errorChangeSketch}
%%            Individual user responses to whether or not they
%%            would change their sketching style}
%% \end{figure}

%User reactions to other types of errors corroborate a trend that
%confusion leads to rejection of the system.  Expressing angst over the
%unpredictability of the randomly generated mislabel errors, one user
%asserted that "[he] would probably not change [his drawing] techniques
%to match the tool, [he'd] just not use the tool."  This user also
%specifically explained that his acceptance of the system would depend
%on the predictability of errors.  Another user expressed similar angst
%with mislabel errors and commented that they were   ; this user was willing to adapt his style to the
%system but explains that the lack of a correct or incorrect label
%fails to enable him to change his style.  


%%  and the final user requested support for debugging
%% circuit connections.  The remaining user specifically requested a 'netlist'
%% feature that would allow a user to visually highlight and debug
%% connections between symbols.  This 'netlist' feature would both aid in
%% the verification of a circuit design and help users detect grouping
%% errors.
  



%-------------------------------------------------------------------------
%% \section{Error Analysis}
%% \textit{This stuff should be integrated into the text above, rather
%%   than presented as one big disclaimer at the end.  I've tried to do
%%   this and commented out the stuff that I think is integrated (see
%%   comments in the latex source).  Are
%%   any of our results statistically significant?}

% I think I covered most of this paragraph in the first part of the
% results section. 
%% Most of our survey data fails to provide a statistically significant
%% foundation for the identification of solid trends in user preferences.
%% Furthermore, in some cases our users presented conflicting viewpoints
%% in response to qualitative questions.  Most traditional evaulation
%% techniques and questionaires measure the overall performance of an
%% application with respect to well-established axes of macroscopic
%% system characteristics (I have no reference for this, its just an
%% observation).  However, our study breaks new ground in attempting to
%% inform system design through the juxtaposition of contrasting
%% interface elements.  Through our evaluation measures and experimental
%% methodology, we have more effectively illuminated apposite axes of
%% interface element characteristics than measured against an existing
%% metric.

% This paragraph is covered with the presentation of results.
%% The unreliability of the Check-Tap gesture confounded user reactions
%% to Recognition Triggers and Annotation Tools.  This confounding
%% prevents conclusively determining one Recognition Trigger or one
%% Annotation Tool as maximally efficacious.  However, our inquiry
%% illuminates how the efficacy of Recognition Triggers and Annotation
%% Tools are directly related to how well these interface elements
%% support efficient work.  Despite the exceptionally high gesture error
%% rate observed, the emphasis of user responses on the importance of
%% reliability suggest that gestures may make inherently impractical
%% Recognition Triggers.  Furthermore, qualitative user feedback
%% comparing the Color and Lasso Annotation Tools emphasizes users'
%% preference for efficiency and simplicity.  Users see convience and
%% novelty as secondary characteristics.

% Incorporated above.
%The implementation of the Text-Label Feedback partially counfounded
%legibility of recognition results.  Two users complained that text
%labels often made recognition results illegible because labels would
%completley obfuscate small gates.  Despite this quirk, any labeling
%method will entail some amount of obfuscation of the sketch.  User
%responses emphasize the importance of the minimization of distracting
%aspects of feedback, therefore any label-based Feedback Mechanism may
%fail to maximize the efficacy of feedback.

%% \textit{Paul: Explain this in the study design and get rid of the text
%%   here.  Justify why it makes sense to allow users to choose their
%%   preferred feedback mechanism (i.e., makes them more likely to spot
%%   errors because they are using the feedback they prefer) instead of
%%   saying it confounds results.}
%% Furthermore, our study of Feedback Mechanisms confounded our study of
%% Error Types.  We did not balance the Feedback Mechanisms used across
%% Error Type study sessions and instead allowed users to choose which
%% method of feedback to use.  Most users preferred and used Color
%% Feedback; the experimenter also invited users to complete part of the
%% Error Type study using the alternate Feedback Mechanism so that users
%% could compare the two.  Three users commented that the visual contrast
%% between symbols provided by Color Feedback helped them spot errors.
%% No user mentioned that either feedback mechanism prevented them from
%% finding errors.  Our study's results emphasize that users desire high
%% visibility of errors.


%% \textit{This text really needs to be incorporated into the dicsussion
%%   of error perception above. I will take care of this.} 

 
%-------------------------------------------------------------------------
\section{Implications for System Design}
The results of our study inform the design of educational sketch
recognition systems.  Here we summarize the major implications for
both user interface and recognition engine developers.  

\textbf{Recognition triggers should be user-triggered, efficient, and
reliable.} Our study illuminates that, with respect to our tasks, users
prefer reliability as much as they do convenience.  Gestures and
system activated recognition may be an option, but should not be the
only option.  

\textbf{The interface should provide users with a way to separate
recognized from unrecognized strokes as they draw.}  Users desire
efficiency and are willing to put in small amounts of effort while they
work to avoid larger amounts of effort later in the process.  Our
study participants preferred our pre-separation tool for its relatively low
mental and physical overhead.

\textbf{Recognition feedback should provide minimal clutter and
transform users' strokes as little as possible.} Stroke color
effectively provides contrast between recognition labels with minimal
stroke transformation.  More dramatic transformation
should occur only upon user request.

\textbf{Users are willing to correct errors after they are done
drawing.}  Our users treated correction as a game or a necessary evil.
Users do error correction all in one batch and tend not want to
disturb their design process with on-the-fly correction (this result
is consistent with~\cite{Hong2002Sketch}).

\textbf{Errors must be predictable and/or understandable.} Automatic
recognition engines can potentially make nonsensical errors.
Recognition engines that incorporate adjustable confidence levels may
help user interface designers strike an optimal balance between false
positives and false negatives.  A recognition engine that could
describe precisely why a given interpretation was missed could also help 
users modify their drawing styles to raise recognition rates.  


\section{Sketch-based Circuit Design User Interface}
Our research group is developing a complete sketch-based tool for
digital circuit design education.  Here we present the user interface
to this tool that we developed according to the results of our user
study.  We also present qualitative results from an additional informal
user study we conducted to evaluate this interface.  The results of this
study confirm many of our previous observations and provide further
insight into user preferences.

\subsection{Interface Overview}
% Prompt/Notes for Paul:
%
%This section will describe the interface and how it was developed
%based on the results of the above study (in particular how we adhere
%to our advice in the previous section).  Talk about how the complete
%system is used and try to point out the novel points of the
%interface--the two-stage recognition, the multi-pane interface to
%support different kinds of recognition, etc.
%main pts:
%* Recognition Button: describe this choice
%* Color Feedback: describe how color by default and text by toggle and text in a 
%non-distracting, activates by hovering
%* multi-panel layout: it's the easiest way to isolate different sketches and annotations
%and users wanted most ease.  
%* two stage recognition: Two-stage recognition is a feature designed to 
%minimize the confusing aspects of errors that troubled users in our preliminary
%study.  (describe these aspects? describe what this feature does).  point to circuit 
%structure recognition engine and its great performance; talk about how the construction
%of circuitrec allows us to give more informative errors. (maybe decouple this info from the main pts
%and give it its own paragraph)

%Additional features:
%* "mesh highlighting": describe
%* error reporting: show pic and describe.  briefly note circuit recognizer 
%architecture and how it enables giving users informative messages
%about errors instead of 'its just wrong.'  May want to note circuit structure
%recognizer performance.

Figure~\ref{fig:newGUI} shows the user interface to our group's
sketch-based digital circuit design tool that we developed. The simulation tool
supports typical introductory circuit design tasks similar to the
truth table tasks discussed above.  Our tool allows
students to sketch circuits freely and then to analyze the behavior of
their recognized circuits via existing simulation software (Xilinx
ISE).  

A typical use case for this interface consists of the following steps.
The student begins by writing notes and equations in the ``notes''
panel on the interface to organize her thoughts.  The system will not
recognize any ink the in the notes panel.

Next, the student draws the corresponding truth table in the ``Truth
Table'' panel, specifying the input and output behavior of the
circuit.  After drawing the truth table, the student taps the
``Recognizer Ink'' button near the top of the interface.  The
application colors recognized strokes in the truth table window to
indicate its recognition, using a separate color for each component in
the table.  (Components include 0's, 1's, X's, labels, and dividers).
The student corrects any recognition errors by erasing and redrawing
her strokes and then retapping the ``Recognize Ink'' button.

After drawing the truth table, the student designs her circuit.
First, the student draws the circuit and then taps on the ``Recognize
Ink'' button to invoke symbol recognition on the circuit diagram; the
application uses color feedback, as described in
Section~\ref{sec:elements}, to convey the result of recognition.  (The
student may also intermittently tap ``Recognize Ink'' to invoke
recognition as she draws her circuit.)  Again, the student corrects
recognition errors by erasing and redrawing strokes and then
reinvoking recognition.  

Once the user has completed drawing the circuit, she taps the
``Recognize Circuit'' button to invoke recognition of the circuit's
structure (which includes wire connections, labeled inputs and
outputs, and other structural features).  The system displays circuit
structure feedback in a number of ways
(Figure~\ref{fig:circuitRecErrorDemo}).  First, the system highlights
the endpoints of connected and unconnected wires in the circuit with
black squares and yellow circles, respectively.
Second, the system alerts the student to any potential structural
problems that may be a result of either misrecognition or incorrect
circuit construction.  Third, when the user selects a wire in the
circuit, the system highlights all other wires that it has detected as
belonging to the same mesh (\textit{mesh highlighting}).  Based on
this feedback, the student corrects errors by erasing strokes, drawing
new strokes, and then invoking both symbolic and structural
recognition on the new strokes.

Finally, the student taps the simulate button.  The system generates
a benchmark test, tests the circuit's behavior against the behavior
specified by the truth table, and alerts the students to any
discrepancies.  Based on the results of this simulation, the student
can modify her original design to fix any conceptual errors.

\begin{figure}[tb]
  \centering
  \includegraphics[width=1.0\linewidth]{summerGUI-with-dot.png}
  \caption{\label{fig:newGUI} User interface for sketch-based digital
         	circuit design application.  The black dot denotes the
         	current location of the user's pen. }
\end{figure}

\begin{figure}[tb]
  \centering
  \includegraphics[width=.85\linewidth]{circuitRec-error-screengrab.png}
  \caption{\label{fig:circuitRecErrorDemo} Demonstration of circuit
           structure feedback, including an error message for an
           illegal circuit structure.}
\end{figure}



\subsection{Design Justification}

We constructed our interface to support the work flow pattern we
observed in our user studies as well as to make recognition feasible.
The three panels in the interface reflect the three major stages we
observed in students' work flow when designing a circuit: notes and
equations, truth table construction, and circuit
design.  The user can toggle the visibility of each panel in order to
devote more screen (drawing) space to one particular diagram.  This
design enforces pre-separation of different types of drawings, which
users in our previous study tended to find a more efficient means of
diagram separation.  Each panel is linked to a different recognition
engine, or no recognition engine in the case of the notes panel,
removing the need for the system to separate circuit elements
from truth tables from notes, and making recognition feasible.

The recognition feedback in our interface aims to display recognition
results clearly while minimizing clutter in the diagram.  We use color
feedback for symbol recognition (in the circuit and truth table
panels) including a text label that the application displays when the
user hovers the stylus near a recognized symbol.  To further minimize
clutter, many of the recognition display options can be toggled on and
off, including the mesh and endpoint highlighting, circuit error
feedback, and text labels for individual symbols.

%Feedback from circuit structure recognition includes highlighting
%connected (and unconnected) wire endpoints with small but conspicuous
%symbols.  (The application highlights unconnected wire endpoints,
%which are not present in the circuit depicted, with red "X" marks).
%Circuit structure feedback also includes a ``Mesh Highlighting"
%feature discussed in detail below.  

We use a two-stage, button-triggered recognition method to help
minimize confusion due to recognition errors by minimizing the
complexity of the errors the user must deal with.  In the first stage,
triggered by the ``Recognize Ink'' button, the system recognizes
individual circuit symbols (e.g., wires and gates).  In the second
stage, triggered by the ``Recognize Circuit'' button, the system links
circuit components together to recognize the structure of the circuit.
Separating these recognition processes provides for more
comprehensible errors because recognition errors from the former stage
will not cascade to and further complicate the errors of the latter
stage (assuming the user corrects all errors).  

Note that while the user sees a two-stage recognition process, the
underlying recognition engine need not make this distinction.
Although in our application we currently separate symbol recognition
from circuit structure recognition, we are exploring ways for the
circuit recognition phase to help correct errors in the symbol
recognition phase before the recognized symbols are displayed to the
user.  

%% recognizer may perform both To
%% illustrate this design, consider the case that the symbol recognizer
%% mislabels the NAND gate highlighted in Figure \ref{fig:newGUI} as a
%% circuit output label called ``D".  In two-stage recognition, the user
%% will notice this error through the unexpected coloring of the NAND
%% gate as a circuit I/O label.  If both symbol and structural
%% recognition were performed as a single process, the structure
%% recognizer would incorrectly presume the highlighted gate as a circuit
%% output, which leads to the incorrect omission of wire endpoints.
%% Furthermore, the structure recognizer would possibly give the user
%% complicated error messages with regards to the circuit's unexpected
%% output ``D" which short-circuits to output ``Y".  Thus the recognition
%% errors that the user must correct in a two-stage process may be
%% simpler and more comprehensible.  Qualitative responses of our
%% preliminary study indicate that users who are willing to correct
%% errors prefer that errors are more comprehensible and predictable.\\


% I think this is already covered above.  -cja
%% Furthermore, the Circuit Simulator provides a Mesh Highlighting
%% feature for debugging circuits and finding structural errors.  The
%% Mesh Highlighting feature thickens the strokes of a circuit element
%% and all connected neighboring elements when the user focuses (hovers)
%% the stylus over a given element.  Figure \ref{fig:newGUI} shows
%% highlighting of the focused NAND gate and its neighboring connected
%% wires.  This feature helps structural errors (e.g. faulty wire
%% connections) appear more conspicuous.  *add more?*


\subsection{Evaluation of Circuit Design Interface}
%This section will describe the results of the informal user study.
%First describe the study and the study's goals (both to verify some of
%the decisions you made when building the interface and also to re-test
%some of the results we got above in a new domain).

This section describes an informal user study evaluating several
features of our new circuit design interface.  We specifically aimed to
assess user preferences for truth table feedback mechanisms, the
multi-panel organization of the user interface, and the mesh
highlighting feature.  In addition, we gathered qualitative feedback on
the overall interface.

We directly compared three feedback mechanisms
for truth table recognition: color feedback, text replacement
feedback, and data table feedback (Figure~\ref{fig:ttFeedback}).    As in
our previous study, color feedback involves coloring each recognized
symbol with a unique color.  Text replacement feedback involves
replacing recognized zeros, ones, and column labels with equivalent
text.  Data table feedback involves drawing a formatted,
spreadsheet-like data table adjacent to the the user's handwritten
table.

\begin{figure}[tb]
 \centering
 \includegraphics[width=.9\linewidth]{mockTruthTableFeedback.png}
 \caption{\label{fig:ttFeedback} Examples of (a) data table
          and (b) text replacement feedback.  Figure~\ref{fig:newGUI}
          gives an example of color feedback. }
\end{figure}

Our participants included twelve Harvey Mudd College engineering
students who had all previously completed digital design coursework
and used standard digital circuit simulation software (e.g. Xilinx
ISE) but had not participated in our first study.  We asked each
participant to complete a truth table task similar to the task in
Figure~\ref{fig:tt-task}.  We requested that the user draw the truth
table and then tap ``Recognize Ink.''  The system recognized the truth
table using our own automatic truth table recognizer and displayed its
feedback using one of three methods described above.  We then showed
the user the same recognition feedback using each of the other two
methods and asked him or her to rank the methods in order of
preference.  We balanced the order in which we displayed feedback
across participants.

We subsequently asked nine of the twelve users to draw the circuit
corresponding to the given truth table in the circuit panel.  (Due to
scheduling conflicts, the first three study participants could not
complete the circuit design portion of the task.)  Because our circuit
recognition engine is still under construction, we again used
simulated recognition for this part of the evaluation, and we informed
users that the system was using simulated recognition.  We simulated
symbol recognition by coloring the user's strokes blue or red to
indicate correct or incorrect ``recognition,'' as in the user study
described in Section~\ref{sec:study1}.  When the user tapped
``Recognize Circuit,'' we replaced his or her diagram with
pre-constructed, pre-labeled version of the same circuit (shown in
Figure~\ref{fig:newGUI}) and asked the user to interact with this
circuit give us qualitative feedback on the mesh highlighting feature.

The results of this study verify several trends in user preferences
observed in our first study.  First, most users (n=9)
preferred color feedback.  The other three preferred data table
feedback and ranked color feedback as their second choice.  No user
ranked text replacement feedback as a first choice.  Users expressed
a diverse set of reasons for preferring color feedback.  One user
specifically explained that he ``[does not] like to have what [he
draws] covered up'' and spoke generally against feedback that entails
any sort of automatic ink replacement.  Two other users
explained that they preferred color feedback for the ease with which
they could verify recognition results.  These users remarked that color
feedback allowed them to ``immediately check'' and ``instantly identify''
the recognition results as correct or erroneous.  Moreover, another
user who preferred color feedback over data table feedback explained
that she found it too hard to compare each element of the data table
with what she wrote.  In contrast, the three users who preferred data
table feedback all found the data table easier to read and verify for
correctness.


%% The unanimous low
%% ranking of the text replacement feedback mechanism may be due in part
%% to how the system performed text layout.  The prototype version of our
%% software used a naive text replacement algorithm that simply scales
%% text characters to completely overlay the stroke(s) to be covered.
%% This algorithm would often produce a jumbled output when users did not
%% draw truth table entries uniformly; most users found the output
%% difficult to read.  (Zeleznik et al. investigate solutions for
%% avoiding this problematic ``ransom note"~\cite{Zeleznik2007Designing}
%% appearance).  \\

Users reacted positively overall to the mesh highlighting feature.
Seven of nine users regarded the feature as useful, including one user
who rated the feature as ``very useful.''  Three users found the
feature slightly distracting due to a display buffering issue that
caused flickering whenever highlighting of the diagram changed.  Five of
nine users requested the ability to toggle this feature for better
control of the appearance of the diagram.  In response to this
feedback, we added the ability to toggle mesh highlighting to our
interface.

While users had no problem drawing their notes, truth tables and
circuits in different panels, users often had to resize panels to get
more screen space for the component they were currently working on.
We propose a menu that toggles the interface between standard window
configurations to support different phases of the design process.  When
we asked users for their thoughts on such an option, they reacted
positively, although which configurations should be included in such a
menu (and whether these configurations should be user-defined) remains
an area for future study.


%% User reactions
%% to the Circuit Simulator's use of panels to separate notes and
%% diagrams indicate that the currently implemented organization of
%% panels needs improvement.  7 of 12 users resized the panels to create
%% more screen space for drawing diagrams, and two users commented that
%% they had inadequate room for drawing their circuit diagrams.  Part of
%% the evaluation of this feature included a demonstration and discussion
%% of a paper prototype for a menu-based control that would toggle the
%% visibility of each drawing panel.  We asked each user to explain her
%% preference between a Pie Menu and a traditional WIMP-style drop down
%% menu.  The feedback of all users indicated that such a menu-based
%% control would adequately alleviate issues surrounding a shortage of
%% screen space; however, users had diverse opinions as to the specific
%% aesthetic and function of the control.  A direct comparison this
%% menu-based control and the Separation Tools examined in User Study 1
%% is a remaining challenge to explore. \\


The results of this study also gave us further evidence of how users
integrate the task of triggering recognition into their workflows.
Eight of the nine users who completed the circuit design task
triggered recognition after drawing the entire circuit.  One user
experimented with the recognition trigger before completing the
circuit; however, we observed no user who frequently triggered
recognition while completing the design task.  These observations are
consistent with the user workflows observed in our original study.  

%
% Notes/quotes from data
%
%explanations of users for color:
%"with colors you could check it against itself", you can "immediately check," 
%"I don't like to have what I drew covered up"
%wants color but 'text overlay would be nice for homework,' would rather "turn in a standard" diagram, another user wanted "standard symbols"
%color "instantly identifies" recognized symbols; wants text replace for presentation/printouts
%it's too hard to go back and forth and check each element in table

%
%non-color: table
%table easier to read
%table easier to check
%table 'easiest to see'

%-------------------------------------------------------------------------
\section{Related Work}


Previous user studies of sketch-based user interfaces focus mainly on
the development or evaluation of complete systems.  Researchers rely
heavily on interviews and ethnographic studies to identify and understand
user preferences of sketch-based computer tools.  For example,
Landay and Myers designed SILK~\cite{landay95SILK}, a sketch-based
system for user interface design, based on the results of a survey of
professional user interface developers.  Newman \textit{et al.} worked
closely with designers throughout the design of
DENIM~\cite{Newman2003Denim}, a sketch-based system for web page
design.  Their interaction with users revealed that web page
development requires very little sketch recognition: DENIM uses
gesture recognition techniques to recognize pages (rectangles) and
links (arrows) but leaves the rest of the user's sketch unrecognized.
Educational software, on the other hand, requires a deeper
understanding of the user's sketches.  

Among work that focuses on interaction with recognition-intensive
systems, a recent study by Zeleznik \textit{et al.} takes an approach very
similar to our own~\cite{Zeleznik2007Designing}.  They present four
different feedback methods for recognized mathematics equations.
Contrary to our results, they find that providing recognition feedback
by changing the colors of users' strokes is insufficient because users
find color ``insufficient to highlight certain
errors''~\cite{Zeleznik2007Designing}.  Instead they argue that the
system should provide feedback by displaying a typeset version of the
equation offset from the users' original stokes.  The difference
between their results and ours likely stems from the difference in
domain.  First, circuit diagrams contain fewer symbols that are more
spread out in space than math equations, making stroke color easier to
distinguish.  Second, unlike circuit diagrams, equations are
essentially one-dimensional, making it feasible to display recognition
feedback below the original equation.  Offsetting recognized symbols
in a circuit diagram likely would clutter the diagram to the point
where the circuit would become difficult to understand.

Evaluation of many other recognition-intensive systems tends to focus
on recognition error rates, and provides only general insight into
user interface issues (e.g., ``users found recognition errors
frustrating'')~\cite{Alvarado2001Preserving,Gennari2005Combining,Hammond2002Tahuti}.
A few researchers, however, have examined system usability in more
detail.  LaViola's evaluation of MathPad$^{2}$, a sketch-based system
that recognizes freely-drawn equations and physical diagrams, reveals
specific user preferences: users like MathPad$^{2}$'s scribble-erase
gesture and find recognition errors frustrating but tolerable for this
task~\cite{LaViola2006Initial}.  Other user studies of
recognition-based systems are currently
underway~\cite{Koile2007Supporting,Tenneson2005ChemPad}.

%% Our Wizard of Oz
%% methogology allows us to simulate a complete recognition system so
%% that we can easily modify user interface elements and determine user
%% preferences for specific interface elements rather than assess the
%% suitability of a completed system for its domain.

Other researchers have studied the usability of pen-based interaction
techniques that are complementary to sketch recognition.  The CrossY
interface~\cite{Apitz04CrossY} explores several novel interface
elements that combine gestures and traditional graphical user
interface components.  Long \textit{et
al.}~\cite{Long00VisualSimilarity} provide a model for measuring the
visual similarity of gestures in an effort to inform effective gesture
design.  Lank and Saund present a model of users' pen-based selection
gestures to inform the design of a faster, more accurate selection
mechanism \cite{Lank2005Sloppy}.  Finally, Zeleznik and Miller propose
a \textit{Fluid Inking} framework that combines several pen-based
interaction techniques in order to create a natural and powerful
interface\cite{Zeleznik2006Fluid}.  The results of these previous
studies are complementary to our results in the creation of a complete
sketch recognition system.

Though little is known about how free sketch recognition
errors affect usability, researchers have studied user perception of
handwriting and speech recognition errors.  Rhyne and Wolf present
early work in this area~\cite{Rhyne1993Recognition}.  More recently,
Frankish \textit{et al.} find that the relationship between error
rates and user acceptance is dependent on the perceived cost to
benefit ratio of a specific task~\cite{Frankish95RecogAccuracy}.  We
expect that the same trend holds for sketch recognition systems.  Wu
\textit{et al.}  find that handwriting task completion time is most
sensitive to error rates above 6\%~\cite{Wu03ChineseCharacterRecog}.
Munteanu \textit{et al.} find a linear relationship between speech
recognition accuracy and the quality of user experience with
webcasts~\cite{Munteanu2006Effect}.  Although we do not examine error
rates specifically, our analysis helps inform user perception of
sketch recognition errors.

Finally, Wizard of Oz techniques are commonly used in the development
of speech-based interfaces, and they are beginning to emerge as a
feasible technique for sketch-based interfaces.  Researchers have used
Wizard of Oz techniques successfully to design and evaluate
speech-based interfaces for many
years~\cite{Dahlback1993Wizard,Gould1983Composing}. Noting the success
of this technique, Klemmer
\textit{et al.} developed the SUEDE toolkit to support Wizard of Oz
studies in speech-based interface development~\cite{Klemmer2000Suede}.
Although we developed our own Wizard of Oz tool for our study, Davis
\textit{et al.}'s SketchWizard takes the first stride towards
constructing a generic, multi-domain tool for conducting
Wizard-of-Oz-based development of sketch-based
systems~\cite{Davis2007SketchWizard}.

\section{Future Work}

Both our initial study and the development of our revised user interface
suggest several important areas for future study.  In this section we
detail the most critical and present suggestions for exploring them.

First, in the immediate future we plan to conduct a larger follow-up
study using the same design as our first two studies to confirm the
trends we observed and to resolve some of the issues with our initial
study implementation.  For example, in our follow-up study we will
allow users to set their own pause time for automatic recognition; we
will choose a gesture that is more reliably recognized, and we will
eliminate unrealistic false-positives (e.g., where the
system ``recognizes'' a wire as a NAND gate) from our error perception
study.

A second critical area for future study is to design an effective
error correction interface.  Error correction difficulty will
surely impact users' perception of a sketch recognition system,
including their acceptance of various types of errors.  However, how
to construct effective sketch recognition error correction interfaces
is an open problem because of the two-dimensional nature of the task.
One-dimensional error correction interfaces such as the Tablet PC TIP
(text-input panel) do not extend easily to a two-dimensional
environment.

%% \begin{figure}[tb]
%%   \centering
%%   \includegraphics[width=.85\linewidth]{circuitsim-correction-mechanism.png}
%%   \caption{\label{fig:correctionMechDemo}
%%            caption.}
%% \end{figure}


In our future work we plan to compare a number of error correction
interfaces, including: 

\begin{itemize}
\item \textbf{Erase and Redraw} Users use a gesture or the eraser of
  the stylus to erase incorrectly recognized strokes and then re-draw
  the misrecognized symbols.
\item \textbf{N-Best} Users select an alternate interpretation for a
  set of misrecognized strokes, either from a list, or by tapping the
  stylus to display alternate interpretations.  
\item \textbf{Trace over} Users trace over misrecognized pieces of the
  sketch, triggering re-recognition of the traced strokes.
\item \textbf{Grouping correction} Users correct grouping errors by
  explicitly grouping incorrectly grouped strokes.  The system then
  re-recognizes the strokes using the revised grouping.  
\end{itemize}

A third related area of future study is to explore how to help users change
their drawing styles to help the system recognize their drawing more
reliably.  None of our users expressed a willingness to learn a
gesture-based command language to draw their circuits, but many
expressed a willingness to slightly change their drawing style to aid
recognition.  How to create an interface that suggests to users how to
modify their drawing styles, and exactly how much users will be willing
to modify their drawing styles remain open questions. 

Finally, our initial study design only begins to address users'
perception of different types of errors, and there is plenty of future
work to be done in this area.  In particular, in our complete
interface we propose a two-stage error correction process that
separates symbolic from semantic errors, but we do not yet know how
users will perceive this process.


% I took this out because it seemed trivial.  -cja
%% A third area for future work is how to integrate recognition feedback
%% with sketch beautification.  Our study results indicate that users
%% tend to prefer minimal visual transformation immediately after
%% invoking recognition; however, several users requested a sketch
%% beautification feature to ``clean up'' the aesthetic appearance of
%% their homework write-ups.  

%% Many existing free-sketch and gesture-based systems provide such 
%% functionality, the user's perspective of the role of beautification is still 
%% poorly understood.  A broader comparison of feedback mechanisms with 
%% sketch beautification and ornamentation features \textit{(I'm thinking of e.g. Saund, Mathpad draws 
%% boxes around recognized equations)} will help further illuminate the 
%% users' preferences and comprehension of sketch transformations.\\






%% Future
%% evaluation of our circuit diagram creation interface will aim to
%% answer two questions along this line.  Firstly, what kinds of errors do users find comprehensible?  Perhaps users 
%% find basic symbol or gesture recognition errors comprehensible 
%% (or acceptable).  However, recognition of complex diagrams or compound
%% series of gestures may result in errors that users find abstruse and 
%% opaque--and these errors are inevitable independent of error rate.  How 
%% do users prefer that a complicated design procedure is reduced into simpler,
%% intuitive steps?\\

%% Furthermore, what premises influence how users inference about 
%% recognition errors?  Some systems use trainable recognizers that give 
%% users intimate experience with a recognizer antecedent to using the 
%% recognizer in the context of the user interface.  Other systems leverage 
%% empirical training data or gesture-based recognition such that users 
%% can immediate use the system without prior experience.  Might user 
%% frustration with errors drop if users must ``practice'' with a 
%% recognition engine before using the software in practice?  And what 
%% do users absorb about recognition systems through extended use?




% Sorry, I couldn't really do much with this text.  If you think I've
% missed something, please let me know.  -cja
%% Recognition errors are inevitable and users' perception of these errors is 
%% vital to acceptance of a system.  Though our study results illustrate that 
%% users are willing to correct and mentally model errors, still very little is 
%% known about how users understand errors.  An ideal system minimizes 
%% user frustration through making identification of errors easy and 
%% intuitive.  Future work should investigate two major 
%% components of error understanding: how the system presents
%% recognition errors and how users expect errors to materialize in 
%% recognition results.\\

%% \textbf{Presentation of Errors.}  An ideal system will attempt to make recognition errors as 
%% conspicuous as possible.  In the case of basic symbol 
%% recognition, the system usually cannot give special 
%% transformation to recognition errors without a deeper 
%% understanding of the diagram that the symbols create.  Our
%% study of feedback mechanisms suggests minimal transformation
%% of user symbols (e.g. through coloring) best enables users to 
%% notice errors in the circuit domain.  However, this issue still warrants 
%% deeper study through direct comparison of additional feedback mechanisms 
%% and broader study across multiple domains. \\

%% Furthermore, in the case that deeper understanding of the user's 
%% diagram or the diagram domain is possible, the system should attempt 
%% to detect and highlight possible logical errors.  \textit{We could mention 
%% that detecting logical errors is tractable using automated reasoning / other
%% AI methods.}  The methods for detecting and reporting such errors 
%% are likely domain-specific but not intractable.  We present a prototype 
%% error reporting mechanism of our Circuit Simulator (depicted in Figure
%% \ref{fig:circuitRecErrorDemo}) to demonstrate a possible direction for 
%% reporting logical errors.  Our system's circuit structure recognizer 
%% is capable of recognizing several types of common structural mistakes 
%% seen in our training data of real student sketches.  The user interface 
%% reports these errors and thickens corresponding diagram symbols.  A 
%% usability study examining the effectiveness and utility of our error 
%% reporting is still pending.\\



%% \textbf{Mental Models of Errors.}  Understanding of how users 
%% mentally model the recognition process is vital to the error reporting 
%% process and influences the design of a recognition engine.  The 
%% results of our study suggest that complicated and surprising errors 
%% may deter users from accepting a system; this result has influenced 
%% the design of our Circuit Simulator's two-stage recognition process.  
%% We hypothesize that reducing the complexity of errors using this
%% method will alleviate user frustration; however, our justification for 
%% this design stems more from the perspective of the system developer
%% (and how she sees attaining low error rates) rather than that of the user.
%% Future evaluation of the Circuit Simulator will 
%% endeavor to verify if users do indeed find comprehensible our 
%% separation of circuit recognition into symbol recognition and 
%% structure recognition stages.  However, more general 
%% questions about user mental models beg answers.  \\
  
%% MathPad$^2$ similarly decomposes the creation of complicated 
%% diagrams into simpler (and more easily recognized) equations and 
%% gestural commands.  Though evaluation of MathPad$^2$ illustrates user
%% acceptance of these design decisions, the reasons that users find 
%% the system design intuitive remain hidden.  A rigorous and multi-domain 
%% examination of how users perceive the recognition process is needed to 
%% develop trustworthy heuristics for system architecture design.  Investigation of 
%% this issue might target two particular questions.  \\

%% Firstly, what kinds of errors do users find comprehensible?  Perhaps users 
%% find basic symbol or gesture recognition errors comprehensible 
%% (or acceptable).  However, recognition of complex diagrams or compound
%% series of gestures may result in errors that users find abstruse and 
%% opaque--and these errors are inevitable independent of error rate.  How 
%% do users prefer that a complicated design procedure is reduced into simpler,
%% intuitive steps?\\

%% Furthermore, what premises influence how users inference about 
%% recognition errors?  Some systems use trainable recognizers that give 
%% users intimate experience with a recognizer antecedent to using the 
%% recognizer in the context of the user interface.  Other systems leverage 
%% empirical training data or gesture-based recognition such that users 
%% can immediate use the system without prior experience.  Might user 
%% frustration with errors drop if users must ``practice'' with a 
%% recognition engine before using the software in practice?  And what 
%% do users absorb about recognition systems through extended use?


% Prompt/Notes
%
%\textit{Here's a list of things we should/could talk about.  We can
%  get ride of the list, I just have it here for organization right
%  now.  To fill in this section take text from your ``State of the
%  Research'' document}
%\begin{itemize}
%\item Error Correction (see text below) and cite aaron's paper~\cite{Wolin2007Labeler} about how correction that way is good?
%\item Error understanding (futher exploration).  \textit{Paul's note: continue the point raised about
%two stage recognition and mesh highlighting as means for reducing frustration with errors.  Explain
%how accurate CircuitRec is and what kind of informative results it can give (e.g., not just recognition, 
%but detailed error messages).  Thus we argue that our approach is one way to 
%make errors more understanable.}
%\item Domain specific feedback (along the lines of mesh
%  highlighting--what else from the domain might be displayed and how
%  does this interact with the symbol interpretation.  This idea
%  relates to the two-stage recognition process.  To get an
%  understanding of how users will respond to this multi-stage
%  recognition, we need a better understanding of their mental model.
%  Do they think about the recognition process naturally in these two
%  phases?  How might we find out?)
%\item (Other stuff from the state of the research document. )
%\end{itemize}


\section{Conclusion}

We have presented the first direct comparison of user interface
elements in a sketch-based user interface.  We found that users prefer
to trigger recognition at the end of a task and to have segregated
sections for different tasks (schematic, annotation). Users also
prefer a tool that does not clutter or modify their sketch and that
has predictable recognition errors. Our study indicates that features
common in traditional schematic-entry systems, such as mesh
highlighting, are also useful in a sketch-based interface.  These
results have direct implications for the design of free-sketch
interfaces, both in circuit design and a variety of other domains.
Based on these results we constructed a free-sketch user interface for
a digital circuit design tool.

While our study reveals a number of important results, perhaps its
most important outcome was the excitement users showed for a
sketch-based user interface to replace the cumbersome interface they
currently use.  The major advantage they perceived in a sketch-based
interface is the lower cognitive load in entering their circuits, and
they expressed a willingness to cope with and correct the recognition
errors inherent with such a system.

%-------------------------------------------------------------------------
\section{Acknowledgements}
We would like to thank our study participants and Kris Karr (our
Wizard).  We would also like to thank Susan Matonosi and Deb Mashek,
who provided helpful feedback on our study design, and the rest of the
HMC Sketchers group including Anton Bakalov, Andrew Danowitz, Sam
Gordon, Ellen Kephart, Raquel Robinson, Devin Smith, and Alice Zhu.
This work is supported in part by an NSF CAREER award (IIS-0546809),
the Baker Foundation and a Harvey Mudd College Beckman Research Award.


%-------------------------------------------------------------------------




%
% NOTES
%

% User A = Roz 
% User B = Pokey
% User C = Elton
% User D = Jason
% User E = Mackenzie
% User F = Thomas
% User G = Heather
% User H = Matt W
% User I = Max P



%max
%one user 4 sec pause is too long
%one user 10-15 check taps before a go
%more than 10 gates, would trigger more than once, but can get everything in his head as it is
%5-10 checks before it worked for annotation mech
%says it is more natural to have notes in sketch
%no tablet in e85, but yes tablet experience

%pokey yes tablet
%5 times check tap till worked
%10+ check taps in annotatio mech

%RB no tablet
%2/2 in tuturial, then 5 bad checktaps
%"I like the dot" the dot is emphatic
%errs-> "I always feel like I lose when it turns red"
%button has "all the benefits of the check-tap [trigger] but non of the bad stuff"
%five checktap failures in annotations

%MW e85 tutor, no tablet
%6 for 6 on checktap
%"marginal difference" but did prefer it cuz it was easier, liked manually doing checktap
%4 sec pause too long
%1/6 on color tool, 1/3 on lasso tool
%asso is "a little too much work"

%heather yes tablet
%check tap 3/4 during tutorials
%then 1/4 and 3/7, and then 7/10 for lasso



\bibliographystyle{elsart-num-sort}
\bibliography{UserStudyPaper-bibio}





\end{document}
